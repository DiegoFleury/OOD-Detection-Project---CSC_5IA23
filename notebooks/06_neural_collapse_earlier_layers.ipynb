{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6 (Bonus): Neural Collapse on Earlier Layers (NC1‚ÄìNC5)\n",
    "\n",
    "This notebook studies how **all five Neural Collapse properties** emerge progressively through network depth.\n",
    "\n",
    "| Metric | What it measures | Where computed |\n",
    "|--------|-----------------|----------------|\n",
    "| **NC1** | Within-class variability collapse | ALL layers |\n",
    "| **NC2** equinorm | Class-mean norms equality | ALL layers |\n",
    "| **NC2** equiangularity | Simplex ETF structure | ALL layers |\n",
    "| **NC3** | Self-duality (W ‚âà M) | Penultimate only (needs classifier W) |\n",
    "| **NC4** | NCC agreement with network | ALL layers |\n",
    "| **NC5** | ID/OOD orthogonality | ALL layers (needs OOD data) |\n",
    "\n",
    "Key insight (Papyan et al. 2020; Rangamani et al. 2023):\n",
    "- NC forms **last-to-first** ‚Äî the penultimate layer collapses first\n",
    "- Collapse propagates backward through the network during extended training\n",
    "- Earlier layers may never fully collapse, especially if D < C\n",
    "\n",
    "Reference:\n",
    "> Papyan et al., *\"Prevalence of Neural Collapse during the Terminal Phase of Deep Learning Training\"*, PNAS 2020.\n",
    "> Ben Ammar et al., *\"NECO: Neural Collapse Based Out-of-Distribution Detection\"*, ICLR 2024."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('/content/OOD-Detection-Project---CSC_5IA23'):\n",
    "    !git clone https://github.com/DiegoFleury/OOD-Detection-Project---CSC_5IA23/tree/contente/\n",
    "%cd /content/OOD-Detection-Project---CSC_5IA23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch torchvision matplotlib seaborn scikit-learn pyyaml imageio tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "\n",
    "from src.models import ResNet18\n",
    "from src.data import get_cifar100_loaders\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "if device == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('configs/config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(yaml.dump(config, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "- **CIFAR-100** (ID) ‚Äî for NC1‚ÄìNC4\n",
    "- **SVHN** (OOD) ‚Äî for NC5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID data: CIFAR-100\n",
    "print(\"Loading CIFAR-100 (ID)...\")\n",
    "\n",
    "train_loader, val_loader, test_loader = get_cifar100_loaders(\n",
    "    data_dir=config['data']['data_dir'],\n",
    "    batch_size=config['training']['batch_size'],\n",
    "    num_workers=config['data']['num_workers'],\n",
    "    augment=False,\n",
    "    val_split=config['training']['val_split']\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Test batches:  {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OOD data: SVHN (for NC5 computation at each layer)\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "ood_transform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.5071, 0.4867, 0.4408],\n",
    "        std=[0.2675, 0.2565, 0.2761]\n",
    "    ),\n",
    "])\n",
    "\n",
    "print(\"Loading SVHN (OOD for NC5)...\")\n",
    "svhn_dataset = torchvision.datasets.SVHN(\n",
    "    root=config['data']['data_dir'], split='test',\n",
    "    transform=ood_transform, download=True,\n",
    ")\n",
    "svhn_loader = torch.utils.data.DataLoader(\n",
    "    svhn_dataset, batch_size=config['training']['batch_size'],\n",
    "    shuffle=False, num_workers=config['data']['num_workers'],\n",
    ")\n",
    "print(f\"SVHN test samples: {len(svhn_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet18(num_classes=config['model']['num_classes'])\n",
    "\n",
    "checkpoint_dir = config['paths']['checkpoints']\n",
    "checkpoints = glob.glob(os.path.join(checkpoint_dir, 'resnet18_cifar100_*.pth'))\n",
    "\n",
    "def get_epoch_num(path):\n",
    "    match = re.search(r'epoch(\\d+)', path)\n",
    "    return int(match.group(1)) if match else 0\n",
    "\n",
    "latest = max(checkpoints, key=get_epoch_num)\n",
    "epoch_num = get_epoch_num(latest)\n",
    "\n",
    "ckpt = torch.load(latest, map_location=device, weights_only=False)\n",
    "if isinstance(ckpt, dict) and 'model_state_dict' in ckpt:\n",
    "    model.load_state_dict(ckpt['model_state_dict'])\n",
    "elif isinstance(ckpt, dict) and 'state_dict' in ckpt:\n",
    "    model.load_state_dict(ckpt['state_dict'])\n",
    "else:\n",
    "    model.load_state_dict(ckpt)\n",
    "\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"‚úÖ Loaded: {os.path.basename(latest)} (epoch {epoch_num})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.neural_collapse.nc_earlier_layer import (\n",
    "    analyze_layers_single_checkpoint,\n",
    "    analyze_layers_across_checkpoints,\n",
    "    plot_nc_by_layer,\n",
    "    plot_nc_layers_across_epochs,\n",
    "    plot_nc_heatmap,\n",
    "    save_layer_metrics_yaml,\n",
    "    LayerNCResult,\n",
    "    LayerNCTracker,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ NC earlier layer module imported!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figures_dir = os.path.join(config['paths']['figures'], 'nc_layers')\n",
    "metrics_dir = config['paths']['metrics']\n",
    "os.makedirs(figures_dir, exist_ok=True)\n",
    "os.makedirs(metrics_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. NC1‚ÄìNC5 Across Layers (Final Checkpoint)\n",
    "\n",
    "ResNet-18 architecture:\n",
    "\n",
    "| Layer | Feature dim D | Spatial | D vs C=100 |\n",
    "|-------|--------------|---------|------------|\n",
    "| layer1 | 64 | 32√ó32 | D < C ‚ö†Ô∏è NC1 ill-conditioned |\n",
    "| layer2 | 128 | 16√ó16 | D > C |\n",
    "| layer3 | 256 | 8√ó8 | D > C |\n",
    "| layer4 | 512 | 4√ó4 | D > C |\n",
    "| penultimate | 512 | (GAP) | D > C |\n",
    "\n",
    "Features at each layer are Global-Average-Pooled to (B, D) before computing metrics.\n",
    "NC5 uses SVHN as OOD data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üî¨ Computing NC1‚ÄìNC5 at each layer (final checkpoint)...\")\n",
    "print(f\"   Model: ResNet-18 / CIFAR-100 (epoch {epoch_num})\")\n",
    "print(f\"   OOD: SVHN (for NC5)\")\n",
    "print(f\"   Device: {device}\")\n",
    "print()\n",
    "\n",
    "layer_results = analyze_layers_single_checkpoint(\n",
    "    model=model,\n",
    "    loader=train_loader,\n",
    "    device=device,\n",
    "    num_classes=config['model']['num_classes'],\n",
    "    layer_names=['layer1', 'layer2', 'layer3', 'layer4'],\n",
    "    include_penultimate=True,\n",
    "    ood_loader=svhn_loader,   # ‚Üê enables NC5 at every layer\n",
    ")\n",
    "\n",
    "# Print full table\n",
    "print(f\"{'Layer':<14s} {'D':>4s} {'NC1':>9s} {'NC2norm':>9s} {'NC2ang':>9s}\"\n",
    "      f\" {'NC3':>9s} {'NC4':>9s} {'NC5':>9s}\")\n",
    "print(\"-\" * 80)\n",
    "for r in layer_results:\n",
    "    nc3 = f\"{r.nc3_w_m_dist:.4f}\" if r.nc3_w_m_dist is not None else \"    ‚Äî\"\n",
    "    nc4 = f\"{r.nc4_ncc_mismatch:.4f}\" if r.nc4_ncc_mismatch is not None else \"    ‚Äî\"\n",
    "    nc5 = f\"{r.nc5_orthodev:.4f}\" if r.nc5_orthodev is not None else \"    ‚Äî\"\n",
    "    print(f\"{r.layer_name:<14s} {r.feature_dim:>4d} {r.nc1:>9.4f} \"\n",
    "          f\"{r.nc2_equinorm:>9.4f} {r.nc2_equiangularity:>9.4f} \"\n",
    "          f\"{nc3:>9s} {nc4:>9s} {nc5:>9s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full bar chart: NC1‚ÄìNC5 per layer (2√ó3 grid)\n",
    "fig_bars = plot_nc_by_layer(\n",
    "    layer_results,\n",
    "    title_suffix=f\" ‚Äî Epoch {epoch_num}\",\n",
    "    save_dir=figures_dir,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"LAYER-WISE NC1‚ÄìNC5 ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# NC1 progression\n",
    "print(\"\\n--- NC1: Activation Collapse (shallow ‚Üí deep) ---\")\n",
    "for r in layer_results:\n",
    "    bar_len = min(int(r.nc1 / max(lr.nc1 for lr in layer_results) * 30), 30)\n",
    "    bar = \"‚ñà\" * bar_len\n",
    "    note = \"  ‚ö†Ô∏è D < C\" if r.feature_dim < config['model']['num_classes'] else \"\"\n",
    "    print(f\"  {r.layer_name:<14s} (D={r.feature_dim:>3d}) NC1={r.nc1:>8.2f}  {bar}{note}\")\n",
    "\n",
    "# NC4 progression\n",
    "print(\"\\n--- NC4: NCC Agreement (shallow ‚Üí deep) ---\")\n",
    "for r in layer_results:\n",
    "    if r.nc4_ncc_mismatch is not None:\n",
    "        agreement = (1 - r.nc4_ncc_mismatch) * 100\n",
    "        bar = \"‚ñà\" * int(agreement / 100 * 30)\n",
    "        print(f\"  {r.layer_name:<14s} NCC agrees with network: {agreement:.1f}%  {bar}\")\n",
    "\n",
    "# NC5 progression\n",
    "print(\"\\n--- NC5: ID/OOD Orthogonality (shallow ‚Üí deep) ---\")\n",
    "for r in layer_results:\n",
    "    if r.nc5_orthodev is not None:\n",
    "        print(f\"  {r.layer_name:<14s} OrthoDev = {r.nc5_orthodev:.4f}\")\n",
    "\n",
    "# NC3 (penultimate only)\n",
    "pen = next((r for r in layer_results if r.layer_name == 'penultimate'), None)\n",
    "if pen and pen.nc3_w_m_dist is not None:\n",
    "    print(f\"\\n--- NC3: Self-Duality (penultimate only) ---\")\n",
    "    print(f\"  ‚ÄñW^T ‚àí MÃÉ‚Äñ¬≤ = {pen.nc3_w_m_dist:.4f}\")\n",
    "\n",
    "# Monotonicity check\n",
    "nc1_list = [r.nc1 for r in layer_results]\n",
    "monotonic = all(nc1_list[i] >= nc1_list[i+1] for i in range(len(nc1_list)-1))\n",
    "print(f\"\\n‚úÖ NC1 monotonically decreasing: {monotonic}\")\n",
    "\n",
    "ratio = layer_results[0].nc1 / layer_results[-1].nc1 if layer_results[-1].nc1 > 0 else float('inf')\n",
    "print(f\"   NC1 ratio (shallowest / deepest): {ratio:.1f}x\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. NC Propagation Across Training Epochs\n",
    "\n",
    "We compute NC1‚ÄìNC5 at each layer for each checkpoint.\n",
    "This reveals the **temporal dynamics** of how collapse propagates backward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üî¨ Analysing NC1‚ÄìNC5 across layers AND epochs...\")\n",
    "print(f\"   (one forward pass per checkpoint √ó {4+1} layers + OOD pass)\")\n",
    "print()\n",
    "\n",
    "tracker = analyze_layers_across_checkpoints(\n",
    "    checkpoint_dir=checkpoint_dir,\n",
    "    model_class=ResNet18,\n",
    "    loader=train_loader,\n",
    "    device=device,\n",
    "    num_classes=config['model']['num_classes'],\n",
    "    layer_names=['layer1', 'layer2', 'layer3', 'layer4'],\n",
    "    ood_loader=svhn_loader,  # ‚Üê enables NC5 tracking across epochs\n",
    "    checkpoint_pattern='resnet18_cifar100_*.pth',\n",
    "    epoch_regex=r'epoch(\\d+)',\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + tracker.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Line Plots ‚Äî NC per Layer Across Epochs\n",
    "\n",
    "Each line = one layer.  Watch collapse propagate from `penultimate` ‚Üí `layer1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_lines = plot_nc_layers_across_epochs(\n",
    "    tracker, save_dir=figures_dir,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Heatmaps ‚Äî Collapse Propagation\n",
    "\n",
    "Heatmaps (layer √ó epoch) reveal the backward propagation of collapse:\n",
    "darker colours = more collapsed.  Should see the bottom rows (deep layers) darken first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NC1 heatmap\n",
    "fig_hm1 = plot_nc_heatmap(tracker, metric='nc1', save_dir=figures_dir)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NC4 heatmap ‚Äî NCC mismatch across layers\n",
    "fig_hm_nc4 = plot_nc_heatmap(tracker, metric='nc4_ncc_mismatch', save_dir=figures_dir)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NC5 heatmap ‚Äî ID/OOD orthogonality across layers\n",
    "fig_hm_nc5 = plot_nc_heatmap(tracker, metric='nc5_orthodev', save_dir=figures_dir)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NC2 equiangularity heatmap\n",
    "fig_hm2 = plot_nc_heatmap(tracker, metric='nc2_equiangularity', save_dir=figures_dir)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NC2 equinorm heatmap\n",
    "fig_hm3 = plot_nc_heatmap(tracker, metric='nc2_equinorm', save_dir=figures_dir)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 When Does Each Layer Collapse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"COLLAPSE TIMELINE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "pen_final_nc1 = tracker.data['penultimate']['nc1'][-1]\n",
    "threshold = pen_final_nc1 * 2\n",
    "print(f\"\\nThreshold: NC1 < {threshold:.2f} (= 2 √ó penultimate final NC1)\\n\")\n",
    "\n",
    "for layer in tracker.layer_names:\n",
    "    nc1_series = tracker.data[layer]['nc1']\n",
    "    collapse_epoch = None\n",
    "    for i, val in enumerate(nc1_series):\n",
    "        if val < threshold:\n",
    "            collapse_epoch = tracker.epochs[i]\n",
    "            break\n",
    "\n",
    "    if collapse_epoch is not None:\n",
    "        print(f\"  {layer:<14s}: NC1 < {threshold:.2f} at epoch {collapse_epoch}\")\n",
    "    else:\n",
    "        final = nc1_series[-1] if nc1_series else float('nan')\n",
    "        print(f\"  {layer:<14s}: never reached threshold (final NC1 = {final:.2f})\")\n",
    "\n",
    "# NC4 timeline: when does NCC agree >90% with network?\n",
    "print(f\"\\nNC4 timeline: when does NCC agreement > 90%?\\n\")\n",
    "for layer in tracker.layer_names:\n",
    "    nc4_series = tracker.data[layer]['nc4_ncc_mismatch']\n",
    "    agree_epoch = None\n",
    "    for i, val in enumerate(nc4_series):\n",
    "        if not np.isnan(val) and val < 0.10:  # >90% agreement\n",
    "            agree_epoch = tracker.epochs[i]\n",
    "            break\n",
    "    if agree_epoch is not None:\n",
    "        print(f\"  {layer:<14s}: >90% NCC agreement at epoch {agree_epoch}\")\n",
    "    else:\n",
    "        final = nc4_series[-1] if nc4_series else float('nan')\n",
    "        agreement = (1 - final) * 100 if not np.isnan(final) else float('nan')\n",
    "        print(f\"  {layer:<14s}: never reached 90% (final: {agreement:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_layer_metrics_yaml(\n",
    "    tracker,\n",
    "    os.path.join(metrics_dir, 'nc_earlier_layers_metrics.yaml'),\n",
    ")\n",
    "\n",
    "# Single-checkpoint results as JSON\n",
    "import json\n",
    "\n",
    "single_results = []\n",
    "for r in layer_results:\n",
    "    d = {\n",
    "        'layer': r.layer_name,\n",
    "        'feature_dim': r.feature_dim,\n",
    "        'nc1': r.nc1,\n",
    "        'nc2_equinorm': r.nc2_equinorm,\n",
    "        'nc2_equiangularity': r.nc2_equiangularity,\n",
    "    }\n",
    "    if r.nc3_w_m_dist is not None:\n",
    "        d['nc3_w_m_dist'] = r.nc3_w_m_dist\n",
    "    if r.nc4_ncc_mismatch is not None:\n",
    "        d['nc4_ncc_mismatch'] = r.nc4_ncc_mismatch\n",
    "    if r.nc5_orthodev is not None:\n",
    "        d['nc5_orthodev'] = r.nc5_orthodev\n",
    "    single_results.append(d)\n",
    "\n",
    "json_path = os.path.join(metrics_dir, 'nc_earlier_layers_final.json')\n",
    "with open(json_path, 'w') as f:\n",
    "    json.dump({\n",
    "        'epoch': epoch_num,\n",
    "        'ood_dataset': 'SVHN',\n",
    "        'layers': single_results,\n",
    "    }, f, indent=2)\n",
    "print(f\"üíæ Saved: {json_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EARLIER LAYERS NC ANALYSIS ‚Äî FINAL SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nModel: ResNet-18 / CIFAR-100 | OOD: SVHN\")\n",
    "print(f\"Checkpoints analyzed: {len(tracker.epochs)}\")\n",
    "print(f\"Layers: {', '.join(tracker.layer_names)}\")\n",
    "print(f\"Metrics: NC1, NC2 (equinorm + equiangularity), NC3, NC4, NC5\")\n",
    "\n",
    "print(f\"\\n--- Final metrics per layer (epoch {epoch_num}) ---\")\n",
    "print(f\"{'Layer':<14s} {'D':>4s} {'NC1':>8s} {'NC4':>8s} {'NC5':>8s}\")\n",
    "print(\"-\" * 48)\n",
    "for r in layer_results:\n",
    "    nc4 = f\"{r.nc4_ncc_mismatch:.4f}\" if r.nc4_ncc_mismatch is not None else \"  ‚Äî\"\n",
    "    nc5 = f\"{r.nc5_orthodev:.4f}\" if r.nc5_orthodev is not None else \"  ‚Äî\"\n",
    "    print(f\"{r.layer_name:<14s} {r.feature_dim:>4d} {r.nc1:>8.4f} {nc4:>8s} {nc5:>8s}\")\n",
    "\n",
    "# Key observations\n",
    "print(f\"\\n--- Key observations ---\")\n",
    "nc1_list = [r.nc1 for r in layer_results]\n",
    "monotonic = all(nc1_list[i] >= nc1_list[i+1] for i in range(len(nc1_list)-1))\n",
    "print(f\"  NC1 monotonically decreasing (shallow‚Üídeep): {'‚úÖ Yes' if monotonic else '‚ùå No'}\")\n",
    "\n",
    "nc4_vals = [(r.layer_name, r.nc4_ncc_mismatch) for r in layer_results if r.nc4_ncc_mismatch is not None]\n",
    "if nc4_vals:\n",
    "    best_ncc = min(nc4_vals, key=lambda x: x[1])\n",
    "    print(f\"  Best NCC agreement: {best_ncc[0]} ({(1-best_ncc[1])*100:.1f}%)\")\n",
    "\n",
    "nc5_vals = [(r.layer_name, r.nc5_orthodev) for r in layer_results if r.nc5_orthodev is not None]\n",
    "if nc5_vals:\n",
    "    best_nc5 = min(nc5_vals, key=lambda x: x[1])\n",
    "    print(f\"  Best ID/OOD orthogonality: {best_nc5[0]} (NC5={best_nc5[1]:.4f})\")\n",
    "\n",
    "print(f\"\\n--- Files saved ---\")\n",
    "print(f\"  Figures: {figures_dir}/\")\n",
    "print(f\"  Metrics: {metrics_dir}/\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Commit Results to GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git add results/figures/nc_layers/\n",
    "# !git add results/metrics/nc_earlier_layers_*\n",
    "# !git commit -m \"Add Q6 bonus: NC1-NC5 on earlier layers\"\n",
    "# !git push\n",
    "#\n",
    "# print(\"Results committed to GitHub!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
